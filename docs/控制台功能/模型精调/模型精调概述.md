# 模型精调概述
# 精调简介
模型精调泛指 基于基础模型 通过各种训练方法 优化模型提升效果的过程，精调的主要适用场景包括：

* 希望优化模型效果：针对具体场景或任务优化模型效果，提升模型在业务中的表现。
* 希望降低延迟和推理成本：针对场景或任务优化小模型的效果，使精调后的小模型表现接近甚至优于大模型的同时，延迟和推理成本更低。

## 是否应该精调模型

* 评估效果问题是否可通过精调解决：
   * 通用基础能力（如推理、理解、长文）比较难通过精调大幅提升，建议反馈后等待基模优化（[数据合作伙伴demo提交](https://bytedance.larkoffice.com/share/base/form/shrcnRoe6Pc1M6K6YlycyxFWGLd)）。
   * 时效性强的信息检索需求，建议选择联网内容插件，使用请参见[联网内容插件功能说明](/docs/82379/1338552)。
   * 确定域内的信息检索需求，建议选择知识库插件，使用请参见[文档知识问答核心流程](/docs/82379/1261883)。
* 评估收益与成本：
   * 如效果问题集中、判定规则清晰，**建议先尝试通过PE优化提示词**，成本更低、迭代更敏捷 [PromptPilot](https://console.volcengine.com/ark/region:ark+cn-beijing/autope)，详情请见[PromptPilot 概述](/docs/82379/1399495)）。如优化后效果仍不及预期，积累的数据集和评估框架也可用于进一步的精调优化。
   * 精调训练、数据构造成本较高（建议最少 SFT数百样本 、DPO百条样本、CPT一千万 tokens），更大的业务规模能有效摊销训练成本
   * 精调模型推理成本较基础模型更高，如对推理成本非常敏感，请评估后再进行精调或等待基础模型优化。

# 精调选型指南
您可以参考以下条件进行精调模型选型：

1. 根据业务需求，确定满足需求的**模型模态。**
   * 例：需要 文本输入、文本输出，可选择文本生成模型和多模态模型；需要 文本和图片输入、文本输出，可选择多模态模型。
2. 根据所需**模型特性**（如function call、thinking、开源），筛选支持的模型版本。
3. 确定目标**训练方法，​**筛选支持的模型版本。
4. 根据预期的**精调后推理方式**和所需要的**推理上下文窗口**，筛选支持的模型版本。
5. 如无满足需求的版本，尝试放宽筛选条件再次查找。

下面将从选择模型、选择精调类型、数据准备以及选择精调后推理方式四个维度展开详细说明。
## 选择模型
### 模型推荐

* **强烈建议**前期**方案验证时选用较小尺寸的模型**进行精调，成本更低、训练更快、迭代效率更高；当方案验证后，如小尺寸精调模型效果无法满足需求，可再使用更大尺寸的模型进行精调。
* **推荐使用以下主力模型**，调用量大、支持功能全、潜在问题少。

| | | || || ||| \
|**模型** | |**支持特性** | |**精调方法** | |**精调后推理** | | |
|---|---|---|---|---|---|---|---|---|
| | | | | | | | | | \
|模型分类 |\
| |模型版本 |\
| | |thinking模式 |\
| | |[格式说明](/docs/82379/1099461#5d0b79d0) |[函数调用 Function Calling](/docs/82379/1827538#fc9a8ccc) |SFT(LoRA&全量) |\
| | | | |[SFT 最佳实践 - 废弃](/docs/82379/1221664) |DPO(LoRA&全量) |\
| | | | | |[DPO 最佳实践](/docs/82379/1354009) |模型单元 |\
| | | | | | | |批量推理任务 |\
| | | | | | | | |Lora 精调后按token付费推理 |
| | | | | | | | | | \
|**多模态** |\
|支持文本和图片输入，文本输出 |\
| |Doubao-seed-1.6-250615 |\
| | |支持 |\
| | |enabled |\
| | |Disabled |\
| | |auto |支持 |\
| | | | |✅支持LoRA |✅支持LoRA |256k窗口 |256k窗口 |\
| | | | | | | |同基础模型价格 |128k窗口 |\
| | | | | | | | |同窗口基础模型2倍价格 |\
| | | | | | | | | |
|^^| | | | | | | | | \
| |Doubao-seed-1.6-flash-250828 |支持 |\
| | |enabled |\
| | |Disabled |支持 |\
| | | | |✅支持LoRA |✅支持LoRA |256k窗口 |\
| | | | | | | |256k窗口 |\
| | | | | | | |同基础模型价格 |128k窗口 |\
| | | | | | | | |同窗口基础模型2倍价格 |
| | | | | | | | | | \
|**文本生成** |\
|支持文本输入，文本输出 |Doubao-1.5-pro-32k-250115 |不支持，仅disabled |支持 |\
| | | | |✅已支持 |✅已支持 |32k窗口 |32k窗口 |\
| | | | | | | |同基础模型价格 |32k窗口 |\
| | | | | | | | |基础模型2.5倍价格 |
| | | | | | | | | | \
| |Doubao-1.5-lite-32k-250115 |不支持，仅disabled |支持 |✅已支持 |✅已支持 |32k窗口 |32k窗口 |\
| | | | | | | |同基础模型价格 |32k窗口 |\
| | | | | | | | |基础模型2.5倍价格 |

继续预训练、强化学习以及更多模型的精调需求，请[提交工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P00001166)进行咨询。
## 选择精调类型

| | | | | | \
|**方法** |**最小数据需求** |**训练成本** |**难度** |**优势&场景** |
|---|---|---|---|---|
| | | | | | \
|SFT 有监督微调 |数百条以上标注数据(promp+response问答对)  |中 |低 |拟合样本回答，针对性强，效果可控。 |\
| | | | |默认推荐先通过SFT优化。 |
| | | | | | \
|DPO 直接偏好优化 |百条以上偏好对比数据（如 A/B 选择） |中 |中 |基于用户反馈，低成本拟合用户偏好提升用户体验。 |\
| | | | |相比SFT优化偏好成本更低；相比RL无需构建奖励模型。 |
| | | | | | \
|RL 强化学习 |\
|GRPO PPO DAPO |百条以上prompt集 + 可选标注数据 |高 |高 |效果上限高 ，泛化好。 |\
| | | | |需要构建并调优Reward fn，对算法能力要求较高。 |
| | | | | | \
|CPT 继续预训练 |未标注数据一千万tokens以上 |高 |中 |增强行业/垂直领域知识，提升基础效果。 |\
| | | | |需要很大的数据量才有效果，同时对数据质量也有要求。 |

## 数据准备
针对不同精调方法及模型能力，数据集的具体格式规范与要求，请参考[模型精调数据集格式说明](/docs/82379/1099461)。
## 选择精调后推理方式
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/813e3f1e061749acafd35626168bc5ab~tplv-goo7wpa0wc-image.image =100%x)

| || | | | | \
|精调后推理方式 | |使用条件 |性能 稳定性 |价格 |适用场景 |
|---|---|---|---|---|---|
| | | | | | | \
|在线推理 |模型单元 |\
| | |库存紧张，可能买不到。 |\
| | |全量精调产物可以直接买，lora精调产物压缩后才能买。 |使用独占资源，稳定性有保障。 |\
| | | |提供多种模版，客户可基于流量形态选择合适模版和数量调整性能。 |根据使用模型单元数量及型号计价 （方舟模型单元A/B/C/D型）。 |\
| | | | |支持按小时/按月购买。 |小流量效果测试用小规格模型单元； |\
| | | | | |延迟及稳定性要求高的在线生产用分离式部署。 |
|^^| | | | | | \
| |按token后付费 |\
| | |仅部分模型lora训练后支持，不用压缩。 |使用公共资源池，**性能及稳定性保障较弱。** |基础模型推理价格2-2.5倍。 |\
| | | | | |**小流量效果测试优选；** |\
| | | | | |对延迟及稳定性要求相对宽松的在线生产。 |
| | | | | | | \
|离线推理 |批量推理任务 |全量精调产物可以直接发起推理，lora精调产物压缩后才能发起。 |使用每日夜间闲时资源推理，白天在线高峰期可能无进度。 |同基础模型批量推理。 |\
| | | | | |离线效果测试；离线刷数。 |

# 精调计费说明
## 计费方式

   * 计费方式有**按 token 后付费**或者**按算力付费**，详情请参见[精调计费](/docs/82379/1544681#9e85bab6)。

## 计费单价

   * 精调训练、精调后在线推理、精调后批量推理计费单价信息请参见[模型精调](/docs/82379/1544106#b3a42676)。

# 快速开始
在完成选型后，可使用控制台进行精调训练，详细使用信息请参考[创建并查看模型精调任务](/docs/82379/1099460)。
# 常见问题
### 精调任务 没开始训练/在排队/还没训练完
方舟平台使用潮汐闲时资源训练，主要在夜间训练，日间高峰期会被在线负载抢占。
当训练任务较多时，可能会出现一整天都没有训练进度的情况。如有高优重保需求，请[提交工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P00001166)处理。
具体进度可参考 精调任务详情页-时间线。
### Step数和预期不符
SFT、DPO、CPT 默认启用 dyn_bsz参数（Dynamic Batch Size），会将多个样本组合尽量填满seq_len以加快训练效率，实际一个batch训练token数约等于seq_len*batch_size。
如有明确的关闭dyn_bsz需求（如样本量过小且无法获取更多样本），请[提交工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P00001166)处理。
### 训练效果不佳
影响因素较多，常见的包括但不限于：

1. 训练step数过少（如少于50steps）。
2. epoch过多loss过低，过拟合。
3. 训练集样本内容不符合预期（如训练和推理样本格式不一致；thinking能力训练缺少reasoning content；FunctionCall训练带的tools信息有误）。

若排查后怀疑为系统或镜像问题，请[提交工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P00001166)，我们将安排研发协助排查。
### 精调任务报错
请查看报错信息，如为系统原因请[提交工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P00001166)处理。
### 

#