# 机密部署最佳实践
# **机密部署简介**
为了将模型（平台）服务方的安全能力与数据隐私保护能力透传给用户，火山方舟提供机密部署方案。该方案基于硬件可信部署与远程证明（RA）技术，确保用户的推理服务始终运行于受硬件保护的可信环境中，用户可自主验证平台的安全能力，进一步向用户证明其数据 “唯用户可见、唯用户可用”。
# **机密部署优势**

* **芯片级安全隔离**：基于可信执行环境（Trusted Execution Environment，简称TEE）技术，通过硬件级的安全机制，不仅对内存进行加密，还保护寄存器状态和运行时上下文，从而在整个计算过程中为敏感数据提供隔离与防护。即便底层基础设施遭到入侵，数据依然不会被窃取或篡改。在分离式部署的基础上，该技术构建了从物理硬件（GPU/CPU）到容器运行时的全链路安全隔离，杜绝火山方舟的云服务商或者大模型供应商接触数据，让隐私数据在云端获得比本地更安全的计算保障。
* **端到端数据保护**：提供应用层的会话加密服务。在此模式下，用户在火山方舟平台会话中的明文数据（如 Prompt 、 Response等）仅在 TEE 环境中可见。
* **可验证的安全能力**：机密部署继承了方舟安全沙箱的全部技术，并进一步提升安全水位：
   * **增强防护**：机密部署完成后，在安全沙箱内解密后的数据仅在 CPU/GPU 的 TEE 环境中进行处理，能有效抵御来自云基础设施层的攻击。
   * **可信验证**：机密部署完成后，提供远程证明报告供用户下载。用户可使用离线工具手动解析和验证该报告，以验证机密推理部署运行环境的可信性。

# **应用场景**

* **车载助手**：

车载智能助手在拓展智能化应用场景时，受限于端侧大模型的算力瓶颈，需借助云端大模型实现更丰富的功能。机密部署能保障用户隐私数据在端与云之间的安全流转，在充分发挥云端大模型能力的同时，确保敏感信息不被泄露。

* **智能客服**：

智能客服需处理大量用户个人信息、售后保障等隐私数据。调用公有云模型时，企业常因数据安全风险而难以推进方案落地。机密部署可在可信环境中部署AI模型，确保隐私数据不出域，同时支持智能客服高效、安全地调用知识库。
# 机密部署启用与验证
## 1.开启机密部署

* **创建推理接入点：​**在[火山方舟控制台](https://console.volcengine.com/ark/region:ark+cn-beijing/endpoint?config=%7B%7D)点击**创建推理接入点**。

<div style="text-align: center"><img src="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5c88aed8f6764902ac87e3b5c0d11d57~tplv-goo7wpa0wc-image.image" width="2830px" /></div>

* **选择模型**：在模型列表中，选择 **Doubao-Seed-1.6**（未来预计开放更多模型支持）
* 接入模式：选择**模型单元。**
* 输入类型：当输入内容为纯文本的时候，您应选择的输入类型为**文本**；若接入多模态模型，您可以根据实际业务需要选择**文本**、**图像**输入类型中的一个或多个。

<div style="text-align: center"><img src="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/b7b6635d8fcf477dabae29e255100cec~tplv-goo7wpa0wc-image.image" width="1944px" /></div>

* **选择部署方式及配置资源**：
   
   | | | | \
   |输入类型 |部署方式 |配置资源 |
   |---|---|---|
   | | | | \
   |输入类型为**文本** |**AICC机密部署-LLM** |   * 配置 **Decode 和 Prefill 两项**。 |\
   | | |   * Decode 和 Prefill的选项配置**需至少8卡起步**。 |\
   | | |   * “弹性设置”为可选项，可按需配置。 |
   | | | | \
   |输入类型包含**图像** |**AICC机密部署-VLM** |   * 配置 **Decode 和 Prefill 及Encoder三项**。 |\
   | | |   * Decode 、Prefill和Encoder的选项配置**需至少8卡起步**。 |\
   | | |   * “弹性设置”为可选项，可按需配置。 |

* **完成创建**：确认配置并下单，系统将自动完成部署，此过程通常需要约10分钟。

## 2.可信验证报告
:::tip
当您创建了机密部署推理点后，**安全审计页面**会自动为您展示部署节点的验证报告，您也可通过以下方式自主验证报告的真实性与一致性：
a. 手动解析原始Base64报告中的内容，与下载的base64解析报告内容做一致性对比
b. 手动验证Base64解析报告中的内容，与下载的验证报告内容做一致性对比与进一步分析
:::

* **查看并下载验证报告**

进入目标推理接入点的详情页，选择**安全审计页面**，点击**可信验证报告**，可在列表中查看并下载当前部署环境所有节点的报告。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/eecbcb14820143ddbd723b4bdf7c0287~tplv-goo7wpa0wc-image.image =2786x)

* **手动解析 Base64 原始报告**

:::tip
脚本工具源码需联系销售人员获取。
:::

* **手动验证 Base64 解析报告**

:::tip
脚本工具源码需联系销售人员获取。
:::
## 3.基于TKS密钥的会话加密
:::tip
支持通过Trusted Key Service（TKS）进行会话加密。用户可以依靠SDK在本地私域对推理会话内容进行加密，会话密文安全传输至沙箱后，仅在TEE安全沙箱内存中解密成明文，用于模型推理。安全沙箱内的模型推理结束后，生成的推理结果会由安全沙箱加密，以密文的形式从安全沙箱传输至用户私域，最终由用户通过SDK在本地解密，获取明文推理结果。
:::

* 进入目标推理接入点的详情页，选择**安全审计**页签，点击**TKS加密**。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/aac773c6518b473eb173327e2269901e~tplv-goo7wpa0wc-image.image =1280x)

* 如果没有创建TKS密钥，则需要先创建TKS密钥。创建成功后，根据接入文档调用SDK，推理会话数据应用层加密功能集成在火山SDK中。

:::warning
* 支持语言：目前仅支持Python SDK。
* 版本要求：SDK版本要求为`volcengine-python-sdk 4.0.2x`及以上。您可以通过`pip install 'volcengine-python-sdk[ark]' -U` 获取SDK的最新版本。
* 三方支持：不支持三方SDK（OpenAI SDK不支持原生代码，仅提供参考示例）。
* 能力支持：仅支持火山方舟平台发布的Doubao 1-6文生文对话模型请求，仅支持Chat Completions中单轮/多轮会话，支持流式/非流式、同步/异步接口。
* 方案支持：基于TKS的加密和基于火山私有CA的加密（[推理会话数据应用层加密方案](/docs/82379/1389905)）在SDK中仅支持使用其中一个方案，无法叠加使用。
* 影响事项：
   * 对于不在机密部署环境中的其他服务，**如MCP、联网搜索、tools、Function Calling等功能将无法使用**。
   * 对于内容审核功能，由于需要明文送审，因此**需线下签署协议跳过内容审核**，由模型原生安全能力或外接其他审核保障内容安全，从而实现完整的全链路加密。请先联系您的销售经理跳过内容审核，并且调用时在请求头中传入`x-ark-moderation-scene = aicc-skip` ，否则会报错。
:::
示例代码：
```Python
import os
from volcenginesdkarkruntime import Ark

# 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
# 初始化Ark客户端，从环境变量中读取您的API Key
client = Ark(
    # 此为默认路径，您可根据业务所在地域进行配置
    base_url="https://ark.cn-beijing.volces.com/api/v3",
    # 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
    api_key=os.environ.get("ARK_API_KEY"),
)

# 开启基于AICC TKS的会话加密
os.environ["VOLC_ARK_ENCRYPTION"] = "AICC"

response = client.chat.completions.create(
    # 指定您创建的方舟推理接入点 ID，此处已帮您修改为您的推理接入点 ID
    model="ep-20250917110303-q54wz",
    messages=[
        {
            "role": "system",
            "content": "你是豆包，是由字节跳动开发的 AI 人工智能助手",
        },
        {"role": "user", "content": "请随机输出一个字符"},
    ],
    
    extra_headers={
        'x-is-encrypted': 'true', # 开启基于TKS密钥的会话加密，访问 https://www.volcengine.com/docs/82379/1803071 了解更多。
        "x-ark-moderation-scene": "aicc-skip", # 加上该Header会跳审核，否则会话依然走审核，可能导致报错。
    },
)

print(response.choices[0])
```

* 单击**TKS加密**即可查询TKS审计日志。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/379f1609b6ba48de8479ca3a1c4137b6~tplv-goo7wpa0wc-image.image =1280x)
# 常见问题
**Q: 机密部署支持哪些模型？**
**A:** 目前机密部署功能仅支持 Doubao-Seed-1.6 模型。未来会逐步开放对更多模型的支持。
**Q: 机密部署与原有的分离式部署有何区别？**
**A:** 两者在安全方案和信任基础上有本质区别：

* 分离式部署：采用火山方舟安全沙箱方案。
* 机密部署：在火山方舟安全沙箱方案上，着重优化了环境的完整性和隔离性，旨在解决用户对云端计算服务的信任问题。不仅提供基于硬件的可信执行环境，还提供可验证的证明文件，允许用户自行审计和验证。

**Q: 启用机密部署是否会影响模型推理性能？**
**A:** 以Doubao-Seed-1.6为例，机密部署后的首Token输出时长增加约6%，QPS无较大影响
**Q: 创建后能否在普通部署和机密部署之间切换？**
**A:** 不支持。部署方式在推理接入点创建后即确定，无法直接修改。如果您需要更换部署方式，需要重新创建一个推理接入点。