# 文本向量化

您可以使用文本向量化模型服务，将文本转化为表达文本语义的向量，并通过计算向量计算出文本之间语义差距。在检索、个性化推荐、智能对话等场景进行文本的分类、聚类、检索、生成等自然语言处理任务。
前提条件
[获取 API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey)
[开通模型服务](https://console.volcengine.com/ark/openManagement)
在 [模型列表](/docs/82379/1330310) 获取所需 Model ID
通过 Endpoint ID 调用模型服务，请参考 [获取 Endpoint ID（创建自定义推理接入点）](/docs/82379/1099522)。
快速开始
**文本字符串转换向量**
通过调用`doubao-embedding-text-240715`模型，将输入的文本字符串转换为向量表示，并输出向量维度和前10维数值。
注意
为获得更好性能，建议文本数量总token不超过4096，或者文本条数不超过4。
**输入文本文件逐行转换**
向量化模型可以基于您上传的文档生成嵌入向量。此处以`embedding_text.txt`作为示例文件，您可以通过代码对文本文件逐行转化成向量。
支持模型
当前支持文本向量化的模型请参见[文本向量化能力](/docs/82379/1330310#5fa3ded4)。
应用场景
*
相关技术
通过上述示例完成基础向量生成后，您可以基于使用场景对向量进行更深层次的处理与分析，常用的功能包括相似度计算与维度优化。
相似度计算
Doubao-embedding向量间相似度得分可以使用[余弦相似度](https://baike.baidu.com/item/%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6/17509249)作为计算方式，余弦相似度计算拆分为下面两步：
第一步: 请求doubao-embedding接口得到embedding，将embedding向量L2_norm处理;
第二步: 对norm处理后的向量进行点积计算得到余弦相似度;
向量降维
向量化是通过向量来表征文本、图像等非结构化数据的过程，让计算机能明白语言、图像等的含义。其中标注词义的维度是描述向量化后向量中数字的个数。在文本向量化场景，每个维度对应文本的一个特征。
**维度更多**：以更多独立特征标注词语来捕捉语义细节，提升表征精度。但会导致数据量膨胀，带来更高的存储成本（内存/磁盘占用）和计算开销（相似度计算、模型推理耗时）。
**维度更低**：以更少特征标注词语，可能损失部分细节。但数据量缩减，存储效率与计算速度会提升，资源消耗以及成本更低。
下列模型支持多种维度，您可通过向量降维，选择合适的维度来向量化文本，平衡“语义精度”、”计算速度“与“资源成本”三者成本。
*
示例代码
推荐用法：常规降维方式以`doubao-embedding-text-240715`模型为例，最高维度2560可以压缩到512, 1024, 2048维度存储检索，维度越高越接近最高维度效果。
如何降维度&计算相似度？
降维度: 将embedding接口获取的向量直接截取前dim维度;
计算相似度: 对截取后的embedding做余弦相似度计算;
针对`doubao-embedding-large-text-250515`模型，需要降维后L2归一化使用。模型支持多种嵌入维度：[2048、1024、512、256] ，即使在较低维度下性能下降也较小。
如何降维度&计算相似度？
降维度: 将embedding接口获取的向量直接截取前dim维度;
归一化：使用 L2 归一化统一向量长度，确保余弦相似度计算准确。
计算相似度: 对截取后的embedding做余弦相似度计算;
最佳实践
场景概述
下列程序实现了将查询文本和资料库文本向量匹配的功能。我们以`embedding_text.txt`的多行文本作为资料库，通过调用Doubao-embedding模型生成文本向量。当程序接收到用户的查询文本时，将其向量化并通过余弦相似度匹配资料库的向量，最终返回最相关的前3条文本及对应相似度分数。
第一步：客户端初始化
导入所需的库包，并设置 API Key，为后续的数据处理和分析做准备。
第二步：从文件读取文本并生成向量
读取包含文本的`embedding_text.txt`文件，调用文本向量模型 API 逐行生成文本对应的向量，并将文本和向量保存为 JSON 文件。
第三步：加载预计算的向量数据
从 JSON 文件加载预计算的文本向量数据，为后续的相似度计算做准备。
第四步：定义计算余弦相似度函数和搜索相似文本函数
利用余弦相似度来度量文本之间的相似性，实现了一个基于内容的文本搜索功能。
用户可以通过输入查询文本，检索与该查询文本最相关的文本。
第五步：测试搜索功能
测试搜索功能，调用 `search_similar_text` 函数查询与`query`变量相关的文本，并返回与该查询文本最相关的前 3 条文本及其相似度分数。
结果示例
运行上述程序后，结果将展示与查询文本相似度最高的前3条文本内容，并分别标注其相似度分数。
# 示例：生成向量并搜索
if __name__ == "__main__":
# 生成或加载向量
try:
embeddings = load_embeddings()
print(f"已加载 {len(embeddings)} 条预计算向量")
except FileNotFoundError:
print("未找到预计算向量，将从文件生成...")
embeddings = generate_and_save_embeddings()
# 执行搜索（示例查询：上下文缓存机制）
query = "上下文缓存（Context API）是方舟提供的一个高效的缓存机制，旨在为您优化生成式AI在不同交互场景下的性能和成本。"
results = search_similar_text(query, embeddings, top_n=3)
# 打印结果
print(f"\n搜索查询: '{query}'")
for i, result in enumerate(results, 1):
print(f"\nTop {i} (相似度: {result['similarity']:.4f}):")
print(f"{result['text'][:200]}...")  # 显示前200个字符
# 定义计算余弦相似度函数
def cosine_similarity(a, b):
a = np.array(a)
b = np.array(b)
return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))
# 定义search_similar_text 函数：搜索与查询文本最相似的前N条文本
def search_similar_text(query_text, embeddings, top_n=3):
# 生成查询文本的向量
query_response = client.embeddings.create(
model="doubao-embedding-text-240715",
input=[query_text],
encoding_format="float"
)
query_embedding = query_response.data[0].embedding
# 计算相似度
for item in embeddings:
item["similarity"] = cosine_similarity(item["embedding"], query_embedding)
# 排序并返回结果
sorted_results = sorted(embeddings, key=lambda x: x["similarity"], reverse=True)
return sorted_results[:top_n]
def generate_and_save_embeddings(file_path="embedding_text.txt", output_path="embeddings.json"):
with open(file_path, "r", encoding="utf-8") as f:
texts = [line.strip() for line in f if line.strip()]
# 调用向量化API
response = client.embeddings.create(
input=texts,
# 构建结果并保存
results = [{"text": text, "embedding": data.embedding}
for text, data in zip(texts, response.data)]
with open(output_path, "w", encoding="utf-8") as f:
json.dump(results, f)
print(f"已生成并保存 {len(results)} 条向量至 {output_path}")
return results
# 降维 + L2_norm
def sliced_norm_l2(vec: List[float], dim=2560) -> List[float]:
# dim 取值 512,1024,2048
norm = float(np.linalg.norm(vec[ :dim]))
return [v / norm for v in vec[ :dim]]
# 余弦相似度计算
query_doc_relevance_score_2560d = np.matmul(
sliced_norm_l2(embeddings[0], 2560), #查询向量
sliced_norm_l2(embeddings[1], 2560)  #文档向量
import os
# 导入火山引擎大模型SDK
from volcenginesdkarkruntime import Ark
# 初始化客户端
client = Ark(
api_key=os.environ.get("ARK_API_KEY"),
base_url="https://ark.cn-beijing.volces.com/api/v3"
def encode(
client, inputs: List[str], is_query: bool = False, mrl_dim: Optional[int] = None
):
# 处理查询文本（添加指令模板优化检索性能）
if is_query:
inputs = [f"Instruct: Given a web search query...\nQuery: {i}" for i in inputs]
# 调用API获取原始向量（未归一化）
resp = client.embeddings.create(
model="doubao-embedding-large-text-250515",
input=inputs,
encoding_format="float",
# 转换为张量并降维（截取前mrl_dim维度）
embedding = torch.tensor([d.embedding for d in resp.data], dtype=torch.bfloat16)
if mrl_dim is not None:
assert mrl_dim in [256, 512, 1024, 2048], "仅支持256/512/1024/2048维"
embedding = embedding[:, :mrl_dim]
# 必须执行归一化：L2归一化后才能计算余弦相似度
embedding = torch.nn.functional.normalize(embedding, dim=1, p=2).float().numpy()
return embedding
已加载 7 条预计算向量
搜索查询: '上下文缓存（Context API）是方舟提供的一个高效的缓存机制，旨在为您优化生成式AI在不同交互场景下的性能和成本。'
Top 1 (相似度: 0.9085):
上下文缓存（Context API）通过缓存数据优化AI性能与成本...
Top 2 (相似度: 0.7384):
文本生成可理解文本并进行对话回复...
Top 3 (相似度: 0.7201):
批量推理适用于大计算量非即时任务，享高配额与低价...
# 从环境变量中读取您的方舟API Key
input="Function Calling 是一种将大模型与外部工具和 API 相连的关键功能",
print(f"向量维度: {len(response.data[0].embedding)}")
print(f"前10维向量: {response.data[0].embedding[:10]}")
# 从文件读取文本并生成向量
with open("embedding_text.txt", "r", encoding="utf-8") as f:
# 按行分割文本（每行作为一个独立输入）
print(f"处理文本数量: {len(response.data)}")
print(f"首个文本向量维度: {len(response.data[0].embedding)}")
def load_embeddings(file_path="embeddings.json"):
return json.load(f)
doubao-embedding-large-text-240915
无
4096
支持2048、512, 1024 降维使用
分析用户行为数据并向量化，计算用户兴趣与内容相似度，为用户推荐可能感兴趣的内容。
内容推荐系统
个性化推荐
对大量文本内容向量化后，用聚类算法发现热点话题或流行趋势，为内容创作者提供参考。
热点发现
**模型 ID（Model ID）**
**备注**
**支持维度**
对大量优秀文本向量化学习，根据用户输入推荐词汇、短语或句子，提高写作质量和效率。
辅助写作
对社交媒体等渠道的大量文本数据向量化，快速识别热点话题和公众情绪变化趋势，为决策提供依据。
舆情监测与分析
理解用户问题并向量化，与知识库中的问题进行向量匹配，找到最相关答案。
问答系统
问题理解与答案匹配
在企业知识库、文档库中，基于向量模型快速准确检索员工相关文档。
企业内部搜索
结合知识图谱和文本向量化技术，在知识图谱中高效查询和推理，为用户提供准确答案。
知识图谱问答
对用户发布的内容、评论等行为数据向量化处理，构建用户画像和社交关系网络，支持社交网络个性化推荐等运营。
社交网络与舆情分析
用户画像与社交关系分析
doubao-embedding-text-240515
2048
支持 512, 1024 降维使用
先将文本向量化，再用实体识别模型处理向量，提取关键实体信息用于知识图谱构建等。
命名实体识别
将查询和文档转化为向量，让搜索引擎依据向量语义理解用户意图，返回更相关结果。
信息检索与搜索
搜索引擎优化
将源语言和目标语言的文本向量化，更好地捕捉语义对应关系，提高翻译准确性和流畅性。
机器翻译
doubao-embedding-large-text-250515
需要L2归一化后使用
说明
**L2归一化** 是将向量中每个元素除以该向量的L2范数（即各元素平方和的平方根），使归一化后的向量长度为1，从而消除不同特征间的量纲差异并保留相对大小关系。
支持2048、1024、512、256 降维使用
作为文本生成模型的输入特征，依据给定主题或关键词的向量表示，生成符合逻辑和语境的文本。
文本生成与辅助写作
文本生成
doubao-embedding-text-240715
2560
支持 512, 1024, 2048 降维使用
描述
领域
细分场景
将文本数据输入向量模型得到向量表示，用于新闻分类、情感分析等。
自然语言处理
文本分类
