# 知识问答
本节将介绍如何利用大语言模型，基于已创建的知识库实现问答功能。知识问答适用于智能客服、领域咨询、辅助销售和文案生成等场景。
说明

* 知识库创建完成、文档导入且处理完成后，即代表可以进行知识问答。
* 调用接口前请先完成“[API参考-对接指南](https://www.volcengine.com/docs/84313/1254485)”页面的注册账号、实名认证、AK/SK 密钥获取和签名获取。

# 参数设置
在知识库列表页选择对应的知识库，进入详情页并点击「知识问答」按钮进入测试界面。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/97e37ca428d2468e9cfd03e874449498~tplv-goo7wpa0wc-image.image =1920x)
# 参数说明
测试页面中，左侧为知识问答测试的参数设置模块，右侧为对话的界面。下表为各个参数的详细信息：

| | | | \
|**参数** |**作用** |**取值范围** |
|---|---|---|
| | | | \
|返回文本片数量 |控制最终检索返回的文本片数量。 |\
| |如果没有若打开重排模型，则表示检索返回重排后的 TopN 文本片数量； |\
| |若打开了重排模型，则表示模型排序后的结果的前 K 个文本片，K 为返回的文本片数量。 |如果没有打开重排模型：[1, 200] |\
| | |如果打开了重排模型：[1, Top K] |
| | | | \
|问题改写 |启用后，将基于历史对话对本轮问题进行改写，使其具备更完整的语义信息，检索更准确。 |\
| |**注意：改写问题会增加检索时长和额外的 Tokens 消耗。** |默认关闭 |
| | | | \
|启用重排模型 |控制是否使用重排模型对检索到的文本片进行重新排序。 |\
| |打开重排模型则会获得更准确的问题-文本片相似性的评分，提升检索效果。 |\
| |**打开后检索的时间会略有增长，且与召回文本数量成正比，建议合理设置召回文本数量。** |默认模型：m3-v2-rerank，轻量小模型，推理速度更快 |
| | | | \
|召回数量（Top K） |召回是指从海量的候选文本片中找出与问题最相关的 K 个文本片的过程。仅在打开了重排模型的时候可设置此项。建议设置召回数量略大于返回文本片数量，可提高生成准确性。 |[1, 200] |
| | | | \
|更多参数-Dense Weight |在创建知识库时，如果选择的向量化模型和索引算法支持混合检索，则检索时系统会同时考虑问题与候选文本片的语义相关性和字面上的匹配程度，获得更准确的检索结果。 |\
| |Dense Weight 参数用于控制检索时语义相似程度的重要性权重，越偏向 1 表示越倾向于语义检索，越偏向 0 则表示越偏向于关键词匹配检索。 |[0.2, 1] |
| | | | \
|更多参数-按标签过滤文档范围 |标签过滤文档范围未配置时，表示不做过滤。 |\
| |如希望按照标签过滤文档，可在添加条件中的下拉列表中选择需要过滤的标签名称，并选择对应的过滤条件。 |\
| |**过滤条件**包括六种：包含、不包含、大于、小于、大于等于、小于等于。**条件关系**包括两种：且、或。 |-- |
| | | | \
|文档聚合排序 |启用后，将按照原始文档顺序，对召回的切片进行排序聚合，以保证语序和语义正确。 |\
| |**对于参考资料原文语序敏感的场景建议开启;对于切片内容逻辑独立的场景建议关闭** |默认开启 |
| | | | \
|大模型回答 |控制是否使用大模型总结背景知识回答问题。 |\
| |关闭则返回检索到的文本片，打开则返回基于文本片和 prompt 组装后模型的回答。 |-- |
| | | | \
|拼接邻近文本片数量 |取该值作为召回重排后拼接邻近文本片的数量，若召回重排后文本片数为k，该值为p，则最终返回数量范围为[k，k+2*k*p] |[0, 5] |
| | | | \
|编写 prompt |当打开「使用大模型模型生成回答」时可设置。 |\
| | |\
| |* prompt 编排允许您设置传入大模型模型时如何组装用户问题和检索到的文本片，以及其他的回复要求。 |\
| |* prompt 编排**必须包含**两个变量，使用方括号+变量名作为占位符： |\
| | |\
| |```JSON |\
| |<context> |\
| |  <Documents> |\
| |</context> |\
| |``` |\
| | |\
| | |\
| |* 在组织 prompt 时，您可以给大模型模型一些指示。以贴合您的使用场景。例如，让大模型模型使用检索到的文本作为背景信息回答问题，并在检索到的信息不能回答用户问题时转接人工客服，等等。 |\
| | |\
| |平台也提供了几个核心场景的 prompt 模板并支持一键引用。 |-- |
| | | | \
|API 调用 |保存设置后，您可以点击「API 调用」按钮获得 API 调用的请求体，便于您将调试好的设置嵌入您的应用当中。 |-- |

# 问答测试
模型将检索到的文本片组装到 prompt 编排区域的 prompt 中，再输入大模型模型，由大模型模型根据检索到的背景信息回答问题。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/bbafc278ba9b42e384e26d39838c8184~tplv-goo7wpa0wc-image.image =1920x)
在编写 prompt 的部分，提供了几个核心场景的 prompt 模板，点击应用即可进行对原本 prompt 的覆盖
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/582dfa4cc92f4fb0826dbd159bb17f09~tplv-goo7wpa0wc-image.image =2558x)
对话框下方显示参考文本片的来源文档。点击「召回详情」按钮可以查看检索到的文本片的召回分数和重排分数。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/1fd7ad045c5647bc93d0c448a8c0f091~tplv-goo7wpa0wc-image.image =1920x)
切换可以看到 prompt 组装后最终的完整 prompt。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/bb3920835dd1492595c8821f1080495a~tplv-goo7wpa0wc-image.image =1920x)
检索测试支持多轮对话，可以基于上下文对当前轮输入的问题进行改写，从而得到更准确的问题回复。点击「清空对话」可以清空上下文。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/38b62dc8bc384455af0edbad3de0870f~tplv-goo7wpa0wc-image.image =1920x)
说明

* 开启使用大模型模型时，拼接邻近文本片后，平台会按照文本片的 `doc_id`字段聚合相同来源的文本片，相同来源的文本片按照 `chunk_id` 顺序排列。
* 大模型模型的输入字符数量有限制，为了避免超出限制，系统在组装 prompt 时会截断过长的文本片。请根据选用的大模型模型的输入窗口大小设置合理的返回文本片数量。